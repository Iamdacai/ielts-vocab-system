#!/usr/bin/env node

/**
 * Azure å‘éŸ³è¯„åˆ†æœåŠ¡æµ‹è¯•è„šæœ¬
 * ç”¨äºéªŒè¯å‘éŸ³è¯„åˆ† API åŠŸèƒ½
 */

const axios = require('axios');
const fs = require('fs').promises;
const path = require('path');

// ä» .env æ–‡ä»¶åŠ è½½é…ç½®
require('dotenv').config({ path: '../.env' });

const PRONUNCIATION_CONFIG = {
  apiKey: process.env.PRONUNCIATION_API_KEY,
  region: process.env.PRONUNCIATION_REGION || 'eastasia',
  language: process.env.PRONUNCIATION_LANGUAGE || 'en-US'
};

async function createTestAudio(word) {
  // åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„å½•éŸ³ï¼‰
  // è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç©ºçš„ WAV æ–‡ä»¶ä½œä¸ºå ä½ç¬¦
  const testAudioPath = path.join(__dirname, 'test-recording.wav');
  
  // WAV æ–‡ä»¶å¤´ï¼ˆ44å­—èŠ‚ï¼‰+ ç©ºæ•°æ®
  const wavHeader = new Uint8Array([
    0x52, 0x49, 0x46, 0x46, // "RIFF"
    0x24, 0x00, 0x00, 0x00, // æ–‡ä»¶å¤§å° (36 + 0)
    0x57, 0x41, 0x56, 0x45, // "WAVE"
    0x66, 0x6D, 0x74, 0x20, // "fmt "
    0x10, 0x00, 0x00, 0x00, // fmt chunk size (16)
    0x01, 0x00,             // format (1 = PCM)
    0x01, 0x00,             // channels (1)
    0x80, 0x3E, 0x00, 0x00, // sample rate (16000)
    0x00, 0x7D, 0x00, 0x00, // byte rate (32000)
    0x02, 0x00,             // block align (2)
    0x10, 0x00,             // bits per sample (16)
    0x64, 0x61, 0x74, 0x61, // "data"
    0x00, 0x00, 0x00, 0x00  // data size (0)
  ]);
  
  await fs.writeFile(testAudioPath, wavHeader);
  return testAudioPath;
}

async function testPronunciationAssessment(word = 'hello') {
  console.log(`ğŸ§ª æµ‹è¯• Azure å‘éŸ³è¯„åˆ†æœåŠ¡ - å•è¯: ${word}`);
  
  if (!PRONUNCIATION_CONFIG.apiKey) {
    console.error('âŒ é”™è¯¯: æœªé…ç½® PRONUNCIATION_API_KEYï¼Œè¯·å…ˆåœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®');
    return false;
  }
  
  try {
    // åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    const audioPath = await createTestAudio(word);
    const audioBuffer = await fs.readFile(audioPath);
    
    // å‘éŸ³è¯„åˆ† API ç«¯ç‚¹
    const assessmentUrl = `https://${PRONUNCIATION_CONFIG.region}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=${PRONUNCIATION_CONFIG.language}&format=detailed`;
    
    console.log('ğŸ“¡ å‘é€å‘éŸ³è¯„åˆ†è¯·æ±‚...');
    
    const response = await axios.post(assessmentUrl, audioBuffer, {
      headers: {
        'Ocp-Apim-Subscription-Key': PRONUNCIATION_CONFIG.apiKey,
        'Content-Type': 'audio/wav; codecs=audio/pcm; samplerate=16000',
        'Accept': 'application/json',
        'SpeechContext': JSON.stringify({
          'pronunciationAssessment': {
            'referenceText': word,
            'gradingSystem': 'HundredMark',
            'dimension': 'Comprehensive',
            'enableMiscue': true
          }
        })
      }
    });
    
    console.log('âœ… å‘éŸ³è¯„åˆ†è¯·æ±‚æˆåŠŸ');
    console.log('ğŸ“Š è¯„åˆ†ç»“æœ:', JSON.stringify(response.data, null, 2));
    
    // æ¸…ç†æµ‹è¯•æ–‡ä»¶
    await fs.unlink(audioPath);
    
    return true;
    
  } catch (error) {
    console.error('âŒ å‘éŸ³è¯„åˆ†æµ‹è¯•å¤±è´¥:');
    if (error.response) {
      console.error('çŠ¶æ€ç :', error.response.status);
      console.error('é”™è¯¯ä¿¡æ¯:', error.response.data?.toString() || error.response.statusText);
    } else {
      console.error('é”™è¯¯è¯¦æƒ…:', error.message);
    }
    return false;
  }
}

async function main() {
  console.log('ğŸš€ å¼€å§‹ Azure å‘éŸ³è¯„åˆ†æœåŠ¡æµ‹è¯•\n');
  
  const success = await testPronunciationAssessment('hello');
  
  console.log('\nğŸ“Š æµ‹è¯•æ€»ç»“:');
  console.log(`å‘éŸ³è¯„åˆ†æœåŠ¡: ${success ? 'âœ… é€šè¿‡' : 'âŒ å¤±è´¥'}`);
  
  if (success) {
    console.log('\nğŸ‰ å‘éŸ³è¯„åˆ†æœåŠ¡æµ‹è¯•é€šè¿‡ï¼');
  } else {
    console.log('\nâš ï¸  å‘éŸ³è¯„åˆ†æœåŠ¡æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®åé‡è¯•');
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬
if (require.main === module) {
  main().catch(console.error);
}

module.exports = { testPronunciationAssessment };